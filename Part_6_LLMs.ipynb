{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrDavidL/learning-dhds/blob/main/Part_6_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 6: Large Language Models in Medicine**\n",
        "\n",
        "**Jonathan Theros, BS**  \n",
        "[Jonathan.theros@northwestern.edu](mailto:Jonathan.theros@northwestern.edu)  \n",
        "\n",
        "**Alan Soetikno, BS**  \n",
        "[alan.soetikno@northwestern.edu](mailto:alan.soetikno@northwestern.edu)  \n",
        "\n",
        "**Jay Manadan**\n",
        "\n",
        "**David Liebovitz, MD**  \n",
        "[davidl@northwestern.edu](mailto:davidl@northwestern.edu)  \n",
        "\n",
        "*Northwestern University Feinberg School of Medicine, Chicago, IL*\n",
        "\n",
        "[GitHub Study Guide](https://github.com/DrDavidL/learning-dhds)\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "Medicine is more attuned to machine learning applications outlined in the previous Parts, as they are typically built and trained for very specific applications and easily compared by test characteristics with receiver operating characteristic curves (ROC), evaluated with confusion matrices, etc. However, LLMs are extremely versatile, with a wide variety of out-of-the-box potential use cases. Let’s explore the considerations around large language models a bit more.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fFmcmGJqiVqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. How GPT Models Work\n",
        "\n",
        "Let's explore how GPT models work - they're a bit complicated in their parts yet work surprisingly similarly to how we think in medicine. Here's a step-by-step breakdown:\n",
        "\n",
        "1. **Input Encoding**: Just like how clinicians break down a patient’s story into key data points, GPT begins by slicing input text into tokens—think words or meaningful fragments. These are converted into numerical vectors (embeddings) that encode both meaning and context—similar to how we might tag diagnoses in EMRs, but much richer.\n",
        "\n",
        "2. **Attention Mechanism**: Imagine assembling a differential diagnosis: you focus more on chest pain or dyspnea when evaluating for cardiac issues. GPT does the same: its attention mechanism assigns weights to tokens, highlighting the most relevant parts of the input.\n",
        "\n",
        "3. **Masked Self-Attention**: When generating text, GPT behaves like a clinician reasoning in real-time—you only use information available so far. This mechanism ensures each predicted token only considers what’s been previously generated, reinforcing a logical, causal flow.\n",
        "\n",
        "4. **Feed-Forward Networks**: Just as patient data flows through multiple layers of clinical evaluation (history, exams, consults), GPT passes embedding vectors through successive neural layers. Each layer refines the representation, capturing deeper nuances before producing the final output.\n",
        "\n",
        "5. **Decoding Outputs**: GPT builds its text one token at a time, each choice informed by the cumulative context—akin to writing an assessment and plan, step by logical step.\n",
        "\n",
        "# 2. Deeper GPT Concepts\n",
        "\n",
        "Now, let's look into a few more relevant concepts:\n",
        "\n",
        "1. **Pre-training and Fine-tuning**\n",
        "   - Pre-training is like our basic sciences years - GPT learns general patterns from massive amounts of text\n",
        "   - Fine-tuning is like our specialty training - refining the model for specialty tasks—like medical summaries or bedside documentation.\n",
        "   - This explains why GPTs can handle both everyday conversation and complex medical terminology\n",
        "\n",
        "2. **Position Embeddings**\n",
        "   - We rely on the sequence of events—did chest pain come before eating? GPT does too: each token gets a position vector to preserve order, making contextual sense possible.\n",
        "   - This is crucial for maintaining logical flow in responses\n",
        "\n",
        "3. **Temperature and Sampling Controls**  \n",
        "    Analogous to clinical vs creative thinking modes:\n",
        "   - Low temperature: protocol-driven, predictable outputs.\n",
        "   - Higher temperature: creative, hypothesis-generating responses—like brainstorming rare causes.\n",
        "   - We can adjust this based on whether we need safe, predictable outputs or more innovative thinking\n",
        "\n",
        "4. **Context Window Limitations**\n",
        "   - GPT has a “working memory” limit—like a clinician referencing only recent notes. The context window defines how much prior text it can attend to before older data is forgotten.\n",
        "   - Understanding this helps us use GPT more effectively, just like knowing when to look back at old charts\n",
        "\n",
        "Ready to see these concepts in action? The following exercises will help bring these ideas to life!\n"
      ],
      "metadata": {
        "id": "FJR4DgdRH_jO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Encoding: How GPT Understands Our Medical Text**\n",
        "\n",
        "### From Words to Numbers: Tokenization and Embedding\n",
        "\n",
        "Before GPT can process a medical note, it turns words into numbers—making them machine-readable. This is analogous to how we structure data in EMRs.\n",
        "1. Tokenization: The input text is split into smaller “tokens” (words or subwords).\n",
        "  - \"A 45‑year‑old male with chest pain.\" → [\"A\", \" 45\", \"‑year\", \"‑old\", \" male\", \" with\", \" chest\", \" pain\", \".\"]\n",
        "\n",
        "2. Each token maps to a unique integer ID—like an internal code in GPT’s vocabulary. (like how we use ICD-10 codes!)\n",
        "3. Finally, it creates rich numerical representations (embeddings) that capture the meaning and context\n",
        "\n",
        "Let's see this in action with a typical patient presentation! (Be patient - this will take a minute to download and run the GPT model! Here, you are actually running this full GPT model on your Colab computer!)\n"
      ],
      "metadata": {
        "id": "bsq1QfKXlgeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "# Load our tools\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2Model.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Let's use a familiar clinical scenario\n",
        "text = \"A 45-year-old male with high blood pressure, diabetes, and heart failure presents with chest pain radiating to the left arm, shortness of breath, nausea, and sweating, starting 2 hours ago.\"\n",
        "\n",
        "# Convert to tokens\n",
        "tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "print(\"\\n=== Let's see how GPT breaks down our clinical note ===\\n\")\n",
        "print(\"1. First, it converts our text into token IDs:\")\n",
        "print(tokens[\"input_ids\"])\n",
        "\n",
        "print(\"\\n2. Here's what those numbers actually represent (our tokens):\")\n",
        "decoded_tokens = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"].squeeze().tolist())\n",
        "print(decoded_tokens)\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = model(**tokens).last_hidden_state\n",
        "print(\"\\n3. Finally, it creates rich numerical representations (embeddings):\")\n",
        "print(f\"Shape of embeddings: {embeddings.shape}\")\n",
        "print(\"(Each token gets a 768-dimensional vector to capture its full meaning!)\")\n",
        "\n",
        "# Verify we can reconstruct our original text\n",
        "print(\"\\n4. We can reconstruct our original note from the tokens:\")\n",
        "decoded_text = tokenizer.decode(tokens[\"input_ids\"].squeeze())\n",
        "print(decoded_text)\n",
        "\n",
        "# Look at embedding variance to show different words have different patterns\n",
        "embedding_variance = np.var(embeddings.detach().numpy(), axis=-1)\n",
        "print(\"\\n5. Different words have different patterns in their representations:\")\n",
        "print(\"Variance in embeddings:\", embedding_variance)"
      ],
      "metadata": {
        "id": "jh2lOpUdXXVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What's happening behind the scenes above?\n",
        "- `tokenizer_config.json`: defines how to split text,\n",
        "- `vocab.json`: The dictionary of words/subwords GPT knows\n",
        "- `merges.txt`: Rules for combining subwords (like combining \"dia\" and \"betes\")\n",
        "- `model.safetensors`: The model's learned patterns\n",
        "- `config.json`: The model's architecture blueprint\n",
        "\n",
        "Want to experiment with different clinical scenarios? Try modifying the text about the patient in the cell above!"
      ],
      "metadata": {
        "id": "LVB94Ho3w4X2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Visualizing How GPT \"Thinks\" About Medical Terms**\n",
        "Just as clinicians group related symptoms logically, GPT organizes medical terms based on similarity. By reducing embeddings to two dimensions, we can visualize these relationships."
      ],
      "metadata": {
        "id": "wElZnC_xs2Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get our tokens and their numerical representations\n",
        "decoded_tokens = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"].squeeze().tolist())\n",
        "embeddings_np = embeddings.squeeze().detach().numpy()\n",
        "\n",
        "# Clean up our tokens (remove technical markers and keep meaningful medical terms)\n",
        "cleaned_tokens = []\n",
        "cleaned_embeddings = []\n",
        "\n",
        "for token, embedding in zip(decoded_tokens, embeddings_np):\n",
        "    cleaned_token = token.lstrip(\"Ġ\")  # Remove technical prefixes\n",
        "    if cleaned_token.isalnum():  # Keep only clear, readable terms\n",
        "        cleaned_tokens.append(cleaned_token)\n",
        "        cleaned_embeddings.append(embedding)\n",
        "\n",
        "# Convert to array for processing\n",
        "cleaned_embeddings = np.array(cleaned_embeddings)\n",
        "\n",
        "# Convert high-dimensional embeddings to 2D for visualization\n",
        "# (Like converting a complex patient case into a clear summary)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "reduced_embeddings = pca.fit_transform(cleaned_embeddings)\n",
        "\n",
        "# Create our visualization\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1],\n",
        "           c='lightblue', s=100, alpha=0.6)  # Make points more visible\n",
        "\n",
        "# Add labels with a white background for better readability\n",
        "for i, token in enumerate(cleaned_tokens):\n",
        "    plt.annotate(token,\n",
        "                (reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
        "                bbox=dict(facecolor='white', edgecolor='none', alpha=0.7),\n",
        "                fontsize=11)\n",
        "\n",
        "plt.title(\"How GPT Organizes Medical Terms in Our Case\", fontsize=14, pad=20)\n",
        "plt.xlabel(\"First Principal Component\", fontsize=12)\n",
        "plt.ylabel(\"Second Principal Component\", fontsize=12)\n",
        "\n",
        "# Add a note explaining what we're looking at\n",
        "plt.figtext(0.02, -0.05,\n",
        "            \"Note: Terms that appear closer together are more related in GPT's 'understanding'\\n\" +\n",
        "            \"Just as we group related symptoms, GPT learns to cluster related medical concepts.\",\n",
        "            fontsize=10, ha='left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Let's also print some interesting pairs of words that ended up close together\n",
        "print(\"\\nInteresting patterns in how GPT groups medical terms: sweating, chest, and pain and also heart and nausea!\")\n",
        "# This shows which terms GPT considers related\n"
      ],
      "metadata": {
        "id": "Hobwy1Hd_Be1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What Are We Looking At Above?\n",
        "- Each point represents a medical term from our case\n",
        "- Terms that appear closer together are more related in GPT's \"understanding\"\n",
        "- It’s a simplified 2D snapshot of deeper, higher-dimensional meanings\n",
        "\n",
        "Try analyzing the visualization:\n",
        "1. Do you see any symptom clusters that make clinical sense?\n",
        "2. Are there any surprising relationships in how GPT groups terms?\n",
        "3. How does this compare to how we mentally organize symptoms during differential diagnosis?\n",
        "\n",
        "Want to try different patient presentations to see how GPT organizes other medical concepts? Go back 2 cells earlier, change the text sentence, and re-run both cells! You can also try non-medical content."
      ],
      "metadata": {
        "id": "vCqZfY6WzDFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Example: What Does This Mean in Practice?\n",
        "Imagine typing into ChatGPT: \"A patient presents with chest pain and shortness of breath.\" Here's what happens:\n",
        "\n",
        "1. **Tokenization**: The text is broken into smaller parts, called tokens. For example, \"chest\" becomes one token, while \"pain\" is another.\n",
        "2. **Mapping to IDs**: Each token is mapped to a unique ID that the model understands (e.g., 5827 for \"chest\").\n",
        "3. **Embedding**: These IDs are converted into high-dimensional vectors (e.g., 768-dimensional), capturing semantic meaning and relationships between words.\n",
        "4. **Processing**: The embeddings are passed through the model to generate predictions about the next tokens or text.\n",
        "\n",
        "This is why the tokenized input, token IDs, and embeddings are foundational steps in generating meaningful responses in GPT models.\n"
      ],
      "metadata": {
        "id": "YYpieOo9YA3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding GPT's Attention Mechanism in Medical Context\n",
        "\n",
        "Just as clinicians focus on the most relevant symptoms during a diagnosis, GPT uses an \"attention mechanism\" to decide which parts of the input deserve the most focus. Let’s visualize this concept using a sample clinical sentence.\n",
        "\n",
        "**What we'll do:**\n",
        "- Tokenize a medical text sample (breaking it into meaningful pieces)\n",
        "- Process it through the GPT model\n",
        "- Visualize how the model \"pays attention\" to different words\n",
        "- Interpret relationships GPT draws between terms"
      ],
      "metadata": {
        "id": "8VLiKaSThTdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the GPT-2 model and tokenizer with explicit attention implementation\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2Model.from_pretrained(\n",
        "    \"gpt2\",\n",
        "    output_attentions=True,\n",
        "    attn_implementation=\"eager\"  # Explicitly specify attention implementation\n",
        ")\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Input a medical case description\n",
        "text = \"A patient complains of chest pain and shortness of breath.\"\n",
        "tokens = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "try:\n",
        "    # Process the text through the model (similar to analyzing symptoms)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens, output_attentions=True)\n",
        "\n",
        "    # Extract attention patterns\n",
        "    attentions = outputs.attentions\n",
        "\n",
        "    # Choose which layer and attention head to visualize\n",
        "    layer, head = 0, 0  # First layer, first attention head\n",
        "\n",
        "    # Get the attention matrix and move to CPU for visualization\n",
        "    attention_matrix = attentions[layer][0, head].cpu().numpy()\n",
        "\n",
        "    # Convert model's internal tokens to readable text\n",
        "    tokens_list = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"].squeeze().tolist())\n",
        "    cleaned_tokens = [token.lstrip(\"Ġ\") for token in tokens_list]\n",
        "\n",
        "    # Create an attention heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        attention_matrix,\n",
        "        xticklabels=cleaned_tokens,\n",
        "        yticklabels=cleaned_tokens,\n",
        "        cmap=\"Blues\",\n",
        "        cbar=True,\n",
        "        square=True\n",
        "    )\n",
        "    plt.title(f\"Attention Patterns in Medical Text Analysis (Layer {layer + 1}, Head {head + 1})\")\n",
        "    plt.xlabel(\"Target Tokens\")\n",
        "    plt.ylabel(\"Source Tokens\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Add interpretation helper\n",
        "    print(\"\\nInterpretation Guide:\")\n",
        "    print(\"- Darker colors indicate stronger attention between tokens\")\n",
        "    print(\"- Look for patterns between related medical terms\")\n",
        "    print(\"- Notice how the model connects symptoms with each other\")\n",
        "\n",
        "    # Optional: Print attention statistics\n",
        "    print(\"\\nAttention Statistics:\")\n",
        "    print(f\"Maximum attention value: {attention_matrix.max():.4f}\")\n",
        "    print(f\"Average attention value: {attention_matrix.mean():.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    print(\"Please ensure you have the latest version of transformers installed:\")\n",
        "    print(\"!pip install --upgrade transformers\")"
      ],
      "metadata": {
        "id": "OoqT7Ja4gB_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To give an example of how to interpret this attention map, look at the patient column (not row). The darkest squares are at \"chest\" and \"complains.\" This initial attention layer is noting a relationship between these terms. Let's try one more layer of attention. In the code above, there are two lines enabling a depicture of two different layers. You can comment one or the other above to see the output for the layer. Look above to find these code lines copied below. Then, move the `#` from one of the code lines to the other and run the cell to generate an attention map for the other layer!\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Visualize attention for a specific layer and head\n",
        "layer, head = 0, 0  # Choose the first layer and first head\n",
        "# layer, head = 11, 0  # For the last layer\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k4rB11Cqhpvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A bit more about the layers and heads\n",
        "\n",
        "## Core Concepts: Layers, Heads & Context\n",
        "Think of GPT like a medical team analyzing a complex case:\n",
        "- **Layers** process information with increasing sophistication:\n",
        "  - Early layers → symptom recognition\n",
        "  - Deep layers → complex clinical reasoning\n",
        "  - Each layer \"milks\" more meaning from the input\n",
        "- **Attention Heads**: Each head offers a different view, like consulting multiple specialists.\n",
        "- **Context Building**: GPT understands a word based on what surrounds it—“discharge” means different things in “hospital discharge” vs. “wound discharge.”\n",
        "\n",
        "## Key Questions in Medical AI\n",
        "\n",
        "### 1. \"How do larger models improve understanding?\"\n",
        "Modern models (beyond GPT-2's 12 layers):\n",
        "- Process more context (like considering longer medical histories)\n",
        "- Capture more complex relationships between symptoms\n",
        "- Better understand rare conditions and subtle interactions\n",
        "- BUT: Require more resources and time\n",
        "\n",
        "### 2. \"What makes these models effective?\"\n",
        "Three key features:\n",
        "- **Layer-by-Layer Processing:** Each layer extracts deeper meaning\n",
        "  - Like moving from symptoms → diagnosis → treatment plan\n",
        "- **Parallel Analysis:** Multiple attention heads work simultaneously\n",
        "  - Like specialists collaborating on a complex case\n",
        "- **Context Integration:** Previous information influences interpretation\n",
        "  - Similar to how prior medical history affects diagnosis\n",
        "\n",
        "### 3. \"When do we need bigger vs. smaller models?\"\n",
        "Choose based on:\n",
        "- Task complexity (routine vs. complex cases)\n",
        "- Resource availability\n",
        "- Speed requirements\n",
        "- Accuracy needs\n",
        "\n",
        "## Quick Takeaway\n",
        "Modern GPT models are powerful because they can extract deep meaning from medical text (or any text...) through multiple layers of analysis. While larger models can understand more complexity, choose the right size for your specific medical application."
      ],
      "metadata": {
        "id": "ty0Gxf6pjPqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding How GPT Generates Medical Responses\n",
        "\n",
        "## How Does GPT \"Think\" Through Medical Cases?\n",
        "Just as clinicians process information systematically, GPT analyzes prompts and generates responses step by step.\n",
        "\n",
        "### The Response Generation Process 🔄\n",
        "1. **Input Analysis** (like reviewing patient information)\n",
        "   - GPT “reads” the full prompt and encodes context using attention\n",
        "\n",
        "2. **Token Prediction** (like clinical reasoning)\n",
        "   - Predicts next word/token based on context\n",
        "   - Uses probability distributions to choose options\n",
        "   - Builds response piece by piece, like constructing a clinical assessment\n",
        "\n",
        "3. **Generation Controls**\n",
        "   - `temperature`: Controls randomness. Lower = focused, Higher = creative\n",
        "     - Lower (0.3-0.5): More focused, standard responses\n",
        "       - Best for: Guidelines, protocols, standard care paths\n",
        "     - Higher (0.7-0.9): More diverse, exploratory responses\n",
        "       - Best for: Brainstorming, complex cases, generating differentials\n",
        "   - `top_p`: Filters the next-token options to top % by probability\n",
        "     - Limits which possibilities the model considers\n",
        "     - Like setting a threshold for clinical relevance"
      ],
      "metadata": {
        "id": "sFlMJq5KtbuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "# Initialize our \"medical AI assistant\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Medical scenarios for demonstration\n",
        "medical_prompts = [\n",
        "    \"The first-line treatment for high blood pressure includes\",\n",
        "    \"The differential diagnosis for chest pain includes\",\n",
        "    \"Potential complications of diabetes mellitus include\"\n",
        "]\n",
        "\n",
        "def generate_medical_response(prompt, temp=0.7):\n",
        "    \"\"\"\n",
        "    Generate medical responses with controlled variety\n",
        "    - Low temp (0.3): Standard, protocol-based responses\n",
        "    - High temp (0.7): More comprehensive, varied responses\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=50,\n",
        "        temperature=temp,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Demonstrate different response styles\n",
        "print(\"Standard Protocol Response (temperature=0.3):\")\n",
        "print(generate_medical_response(medical_prompts[2], temp=0.3))\n",
        "print(\"\\nComprehensive Exploration (temperature=0.7):\")\n",
        "print(generate_medical_response(medical_prompts[2], temp=0.7))"
      ],
      "metadata": {
        "id": "he2ehiLbfQej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💡 Key Points for Medical Students\n",
        "\n",
        "(Beyond that GPT-2 isn't very smart!)\n",
        "\n",
        "1. **Foundation of AI Responses**\n",
        "- Models use pre-trained medical and general knowledge\n",
        "- Process information systematically, like clinical reasoning\n",
        "- Build responses incrementally, considering context\n",
        "\n",
        "2. **Temperature Controls Response Style**\n",
        "- Low Temperature (0.3-0.5):\n",
        "  - Generates focused, standard responses\n",
        "  - Ideal for protocol-based answers\n",
        "  - Example: Standard treatment guidelines\n",
        "- High Temperature (0.7-0.9):\n",
        "  - Generates more varied, comprehensive responses\n",
        "  - Better for exploring possibilities\n",
        "  - Example: Building complex differential diagnoses\n",
        "\n",
        "3. **Practical Applications**\n",
        "- Use low temperature for:\n",
        "  - Standard treatment protocols\n",
        "  - Clinical guidelines\n",
        "  - Routine care pathways\n",
        "- Use high temperature for:\n",
        "  - Brainstorming sessions\n",
        "  - Complex case discussions\n",
        "  - Exploring rare possibilities\n",
        "\n",
        "4. **Important Limitations**\n",
        "- Pre-training knowledge may be outdated\n",
        "- Cannot replace clinical judgment\n",
        "- Requires verification against current guidelines\n",
        "\n",
        "5. **Best Practices**\n",
        "- Match temperature to your needs:\n",
        "  - Guidelines → Low temperature\n",
        "  - Brainstorming → High temperature\n",
        "- Always verify generated content\n",
        "- Use as a supplement to clinical knowledge\n",
        "\n",
        "Remember: AI is a tool to enhance, not replace, clinical thinking. The temperature setting helps you control how focused or exploratory the responses will be!\n"
      ],
      "metadata": {
        "id": "IRnreX5sfZhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I think we are ready for a smarter model here!\n",
        "\n",
        "### **Open-Source vs. Private Models**\n",
        "\n",
        "**Accessibility and Cost:**  \n",
        "- **Open-Source Models**: These models are freely available, allowing users to download, modify, and deploy them locally without licensing fees. This democratizes access to advanced AI capabilities, especially for those with limited budgets. As we will see, some of these powerful models can be run on a <2 GB of storage.  \n",
        "- **Proprietary Models**: Access typically requires subscription fees or pay-per-use arrangements. Users interact with these models via APIs, with limited insight into the underlying architecture.\n",
        "\n",
        "**Customization and Control:**  \n",
        "- **Open-Source Models**: Users can tailor the model's architecture and training data to specific needs, fostering innovation and adaptability.  \n",
        "- **Proprietary Models**: Customization is often restricted, with users dependent on the provider for updates and feature enhancements.\n",
        "\n",
        "**Transparency and Security:**  \n",
        "- **Open-Source Models**: The open nature allows for thorough examination of code and data, promoting transparency and enabling users to identify and address potential biases or vulnerabilities.  \n",
        "- **Proprietary Models**: The closed nature can obscure potential biases or security issues, as the internal workings are not open to public scrutiny.\n",
        "\n",
        "**Performance and Resources:**  \n",
        "- **Open-Source Models**: While offering flexibility, they sometimes require significant local computational resources for training and deployment, which can be a barrier for some users.  \n",
        "- **Proprietary Models**: Often trained on extensive datasets using substantial computational power, they can deliver superior performance, especially in complex tasks.\n",
        "\n",
        "**Data Privacy:**  \n",
        "- **Open-Source Models**: Deploying models locally ensures that sensitive data remains in-house, enhancing privacy and compliance with data protection regulations, which is especially important in medicine.  \n",
        "- **Proprietary Models**: Data shared with these models may be processed externally, raising concerns about data privacy and security."
      ],
      "metadata": {
        "id": "zU-K7QguSc_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **LLM Pitfalls**\n",
        "\n",
        "It is important to consider where large language models can lead clinicians and students awry (Omiye et al). Each model has its own performance characteristics that vary based on task.\n",
        "\n",
        "1. **Inaccuracy and Inconsistency**  \n",
        "   - LLMs can generate factually incorrect or inconsistent information, which is particularly concerning in high-stakes medical contexts. For example, ChatGPT showed a consistency rate of 85% in answering pathology board examination-style questions but still produced factual inaccuracies and interpretive errors (Koga et al). Similarly, LLMs often struggle with summarizing medical evidence accurately, leading to factually inconsistent summaries (Tang et al).  \n",
        "\n",
        "2. **Misinformation and Obsolete Data**  \n",
        "   - LLMs can provide outdated or misleading information. In cancer care, for instance, ChatGPT demonstrated a significant error rate and a tendency to provide obsolete data, necessitating expert-driven verification to avoid misinformation (Iannantuono et al). This issue is compounded by the models' inability to distinguish between real and fake information (Deng et al).  \n",
        "\n",
        "3. **Algorithmic Bias and Inequity**  \n",
        "   - The integration of LLMs in medical education and practice can perpetuate existing biases present in the training data, leading to biased outcomes and inequities in healthcare delivery (Abd-alrazaq et al). This is a critical concern as biased algorithms can exacerbate disparities in medical treatment and outcomes.  \n",
        "\n",
        "4. **Overreliance and Plagiarism**  \n",
        "   - There is a risk of overreliance on LLMs, which can lead to reduced critical thinking and problem-solving skills among medical professionals and students. Additionally, the use of LLMs can facilitate plagiarism, as students might use these models to generate content without proper attribution (Abd-alrazaq et al).  \n",
        "\n",
        "5. **Privacy and Ethical Concerns**  \n",
        "   - The use of LLMs raises significant privacy and ethical issues, including concerns about patient consent, data privacy, and legal liability. These models often lack transparency, making it difficult to understand how they generate responses, which complicates their ethical use in clinical settings (Safranek et al, Borkowski et al).  \n",
        "\n",
        "6. **Lack of Contextual Understanding**  \n",
        "   - LLMs are limited in their ability to integrate contextual and external information, comprehend sensory and nonverbal cues, and cultivate rapport and interpersonal interactions, which are crucial in medical education and patient care (Safranek et al).\n",
        "\n",
        "While LLMs hold promise for transforming medical education and practice, their current limitations—such as inaccuracy, misinformation, bias, overreliance, privacy concerns, and lack of contextual understanding—underscore the need for cautious and responsible integration. Continuous model refinement, human oversight, and adherence to ethical guidelines are essential to mitigate these pitfalls and harness the full potential of LLMs in medicine (Karabacak et al)."
      ],
      "metadata": {
        "id": "uZ_Xec0GSvz_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKGDIYQio9ue"
      },
      "source": [
        "# Enough background!\n",
        "## Running an Open Source Local Large Language Model\n",
        "You'll see how we query and retrieve content from an LLM and learn about more features culminating in your own app!\n",
        "\n",
        "We are going to use a small language model that's still pretty smart! Google's Gemma2 and the 2 billion parameter version. Amazingly, we can download and interact with it and it's less than 2 Gb in size!\n",
        "\n",
        "We need a bit of a processing boost, though, and select T4 in the runtime, or you'll be waiting a while for the model to answer!\n",
        "\n",
        "1. Install software on our cloud computer to run the models.\n",
        "2. Download the model (gemma2:2b)\n",
        "3. Interact with the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fkPVu4QWMec9"
      },
      "outputs": [],
      "source": [
        "# We prepare our cloud computer here. We need a special routine to open a terminal, too.\n",
        "!pip install colab-xterm langchain langchain_core langchain-community langchain-ollama --quiet\n",
        "%load_ext colabxterm\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvgPu-LnqI0Q"
      },
      "outputs": [],
      "source": [
        "# The following command will open a terminal for us to use to install software and keep it running in the background.\n",
        "\n",
        "%xterm\n",
        "# After the terminal opens below:\n",
        "# paste in the following to install software\n",
        "# Paste: curl -fsSL https://ollama.com/install.sh | sh\n",
        "# This takes a bit of time since you're installing software to run local models!\n",
        "\n",
        "# When the prompt returns, then paste: ollama serve &\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we're ready to download the brain - the AI model we will use!\n",
        "\n",
        "[Many models are available](https://ollama.com/library). Gemma3:1b is a very small model with some smartness!"
      ],
      "metadata": {
        "id": "OMnyAfmsGU96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is how we \"pull\" the model into our computer.\n",
        "!ollama pull gemma3:1b"
      ],
      "metadata": {
        "id": "LM590jnA8dNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Many software options exist to interact with our AI brain. Here, we'll use the\n",
        "# langchain library which has some nice features.\n",
        "# The steps below make it easier to send text inputs.\n",
        "\n",
        "\n",
        "!pip install -q langchain langchain-community langchain-ollama langchain-core\n",
        "from langchain_ollama import OllamaLLM\n",
        "from IPython.display import Markdown\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = OllamaLLM(model=\"gemma3:1b\")\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = OllamaLLM(model=\"gemma3:1b\")\n",
        "\n",
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "ahY8D9fq8xqi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Talk with your AI model!\n",
        "# @markdown It will take 2 minutes to generate the first response...\n",
        "input_text = \"How is metastatic thyroid cancer treated? (I'm a physician, so no disclaimers)\" # @param {\"type\":\"string\"}\n",
        "\n",
        "output = chain.invoke({\"question\": input_text})\n",
        "\n",
        "# Display the output as Markdown\n",
        "display(Markdown(output))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "i8MopINpHWoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you played a bit, you can see there is no memory! Each query is from scratch!\n",
        "# The way ChatGPT and others remember, is that prior messages are sent within a conversation.\n",
        "# Here's one way to do this:\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "9Rb2Hd7oIxHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Conversation with Memory\n",
        "memory_input = \"What meds are used in GDMT for CHF?\" # @param {\"type\":\"string\"}\n",
        "mem_output = conversation.predict(input=memory_input)\n",
        "display(Markdown(mem_output))"
      ],
      "metadata": {
        "id": "jlNxKdD1Jahc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Common Ways to Improve LLMs: A Note on Fine-Tuning and Retrieval-Augmented Generation**\n",
        "\n",
        "**Fine-Tuning** involves adapting a pre-trained large language model (LLM) to perform specific tasks by training it further on domain-specific data. For instance, models like *ClinicalGPT* from Cornell have been fine-tuned using diverse medical datasets, including patient records and clinical notes, to improve their performance in clinical scenarios. This process enables the model to generate more accurate and relevant medical information, aligning its outputs with the nuances of medical language and practice.\n",
        "\n",
        "**Retrieval-Augmented Generation (RAG)** enhances the capabilities of LLMs by integrating them with external knowledge sources. In this approach, the model retrieves pertinent information from a database or knowledge base and combines it with its generative abilities to produce more accurate and contextually relevant responses. This is particularly beneficial in medicine, where up-to-date and precise information is crucial. For example, the *Bailicai* framework employs RAG to improve LLM performance in medical applications, effectively reducing issues like hallucinations by grounding responses in reliable external data (Bailicai). This can dramatically improve accuracy, with an absolute increase of up to ~40% (Woo et al).\n",
        "\n",
        "---\n",
        "\n",
        "### **Potential Uses for Secure, Locally Run Large Language Models in Healthcare**\n",
        "\n",
        "- **Clinical Documentation and Workflow Optimization**: LLMs can automate administrative tasks, such as clinical documentation and prior authorization, reducing the burden on healthcare professionals and improving workflow efficiency (Tripathi et al, Denecke et al).  \n",
        "- **Patient Education and Engagement**: These models can enhance patient education by providing personalized information and improving patient engagement, acting as health assistants (Tripathi et al, Denecke et al).  \n",
        "- **Diagnostic Assistance and Treatment Recommendations**: LLMs can assist in diagnostics and offer treatment recommendations, supporting clinical decision-making processes. Caution is necessary, as there are multiple pitfalls with unrefined LLMs (Zou et al).  \n",
        "- **Data Handling and Extraction**: LLMs can efficiently handle and extract data from electronic health records, improving the quality of healthcare services and outcomes (Denecke et al, Zou et al).  \n",
        "- **Information Retrieval**: They can be used for retrieving relevant medical information, aiding in research and clinical inquiries (Chen, Al Nazi et al).\n",
        "\n"
      ],
      "metadata": {
        "id": "NZPDje1ZSjy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **References and Further Reading**\n",
        "\n",
        "1. **Abd-Alrazaq, A., AlSaad, R., Alhuwail, D., Ahmed, A., Healy, P. M., Latifi, S., Aziz, S., Damseh, R., Alabed Alrazak, S., & Sheikh, J.** (2023). *Large language models in medical education: Opportunities, challenges, and future directions.* JMIR Medical Education, 9, e48291. [https://doi.org/10.2196/48291](https://doi.org/10.2196/48291)\n",
        "\n",
        "2. **Omiye, J. A., Gui, H., Rezaei, S. J., Zou, J., & Daneshjou, R.** (2024). *Large language models in medicine: The potentials and pitfalls: A narrative review.* Annals of Internal Medicine, 177(2), 210–220. [https://doi.org/10.7326/M23-2772](https://doi.org/10.7326/M23-2772)\n",
        "\n",
        "3. **Tang, L., Sun, Z., Idnay, B., Nestor, J. G., Soroush, A., Elias, P. A., Xu, Z., Ding, Y., Durrett, G., Rousseau, J. F., Weng, C., & Peng, Y.** (2023). *Evaluating large language models on medical evidence summarization.* NPJ Digital Medicine, 6(1), 158. [https://doi.org/10.1038/s41746-023-00896-7](https://doi.org/10.1038/s41746-023-00896-7)\n",
        "\n",
        "4. **Koga, S.** (2023). *Exploring the pitfalls of large language models: Inconsistency and inaccuracy in answering pathology board examination-style questions.* Pathology International, 73(12), 618–620. [https://doi.org/10.1111/pin.13382](https://doi.org/10.1111/pin.13382)\n",
        "\n",
        "5. **Iannantuono, G. M., Bracken-Clarke, D., Floudas, C. S., Roselli, M., Gulley, J. L., & Karzai, F.** (2023). *Applications of large language models in cancer care: Current evidence and future perspectives.* Frontiers in Oncology, 13, 1268915. [https://doi.org/10.3389/fonc.2023.1268915](https://doi.org/10.3389/fonc.2023.1268915)\n",
        "\n",
        "6. **Deng, J., Zubair, A., Park, Y. J., Affan, E., & Zuo, Q. K.** (2024). *The use of large language models in medicine: Proceeding with caution.* Current Medical Research and Opinion, 40(2), 151–153. [https://doi.org/10.1080/03007995.2023.2295411](https://doi.org/10.1080/03007995.2023.2295411)\n",
        "\n",
        "7. **Safranek, C. W., Sidamon-Eristoff, A. E., Gilson, A., & Chartash, D.** (2023). *The role of large language models in medical education: Applications and implications.* JMIR Medical Education, 9, e50945. [https://doi.org/10.2196/50945](https://doi.org/10.2196/50945)\n",
        "\n",
        "8. **Borkowski, A. A., Jakey, C. E., Mastorides, S. M., Kraus, A. L., Vidyarthi, G., Viswanadhan, N., & Lezama, J. L.** (2023). *Applications of ChatGPT and large language models in medicine and health care: Benefits and pitfalls.* Federal Practitioner, 40(6), 170–173. [https://doi.org/10.12788/fp.0386](https://doi.org/10.12788/fp.0386)\n",
        "\n",
        "9. **Karabacak, M., & Margetis, K.** (2023). *Embracing large language models for medical applications: Opportunities and challenges.* Cureus, 15(5), e39305. [https://doi.org/10.7759/cureus.39305](https://doi.org/10.7759/cureus.39305)\n",
        "\n",
        "10. **Wang, G., Yang, G., Du, Z., Fan, L., & Li, X.** (2023). *ClinicalGPT: Large language models finetuned with diverse medical data and comprehensive evaluation.* arXiv. [https://arxiv.org/abs/2306.09968](https://arxiv.org/abs/2306.09968)\n",
        "\n",
        "11. **Long, C., Liu, Y., Ouyang, C., & Yu, Y.** (2024). *Bailicai: A domain-optimized retrieval-augmented generation framework for medical applications.* arXiv. [https://arxiv.org/abs/2407.21055](https://arxiv.org/abs/2407.21055)\n",
        "\n",
        "12. **Woo, J. J., Yang, A. J., Olsen, R. J., Hasan, S. S., Nawabi, D. H., Nwachukwu, B. U., Williams, R. J., & Ramkumar, P. N.** (2024). *Custom large language models improve accuracy: Comparing retrieval augmented generation and artificial intelligence agents to non-custom models for evidence-based medicine.* Arthroscopy. [https://doi.org/10.1016/j.arthro.2024.10.042](https://doi.org/10.1016/j.arthro.2024.10.042)\n",
        "\n",
        "13. **Tripathi, S., Sukumaran, R., & Cook, T.** (2024). *Efficient healthcare with large language models: Optimizing clinical workflow and enhancing patient care.* Journal of the American Medical Informatics Association. [https://doi.org/10.1093/jamia/ocad258](https://doi.org/10.1093/jamia/ocad258)\n",
        "\n",
        "14. **Denecke, K., May, R., & Romero, O.** (2023). *Potential of large language models in health care: Delphi study.* Journal of Medical Internet Research, 26. [https://doi.org/10.2196/52399](https://doi.org/10.2196/52399)\n",
        "\n",
        "15. **Zou, S., & He, J.** (2023). *Large language models in healthcare: A review.* In 2023 7th International Symposium on Computer Science and Intelligent Control (ISCSIC) (pp. 141–145). [https://doi.org/10.1109/ISCSIC60498.2023.00038](https://doi.org/10.1109/ISCSIC60498.2023.00038)\n",
        "\n",
        "16. **Chen, S.** (2024). *Potential applications and safety of large language models in healthcare.* Interdisciplinary Humanities and Communication Studies. [https://doi.org/10.61173/f578jp05](https://doi.org/10.61173/f578jp05)\n",
        "\n",
        "17. **Al Nazi, Z., & Peng, W.** (2023). *Large language models in healthcare and medical domain: A review.* arXiv. [https://doi.org/10.48550/arXiv.2401.06775](https://doi.org/10.48550/arXiv.2401.06775)\n"
      ],
      "metadata": {
        "id": "wJIr8UKjTi-P"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}