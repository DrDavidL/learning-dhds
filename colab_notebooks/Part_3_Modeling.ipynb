{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrDavidL/learning-dhds/blob/main/Part_3_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cpUyiFUIGUC"
      },
      "source": [
        "- Author: David Liebovitz, MD  \n",
        "- Additional code updates and comments contributed by Xinyang(Oliver) Zhou, Northwestern Univ.\n",
        "- Updated by Jay Manadan\n",
        "-For Northwestern University Feinberg School of Medicine  \n",
        "-May use with attribution\n",
        "\n",
        "[Part 1](https://drive.google.com/file/d/1N9U5NybETiu6JdUBoiFvuLiZZ6UuG0Nx/view?usp=sharing), [Part 2](https://drive.google.com/file/d/1JGePTrMJfnjH4WWpu_F77Oy_rLRR2pCW/view?usp=sharing), [Part 3](https://drive.google.com/file/d/1UrGbYapImkuFA4RTp1rYC1zLCaCgaAxQ/view?usp=sharing),\n",
        "[Part 4](https://drive.google.com/file/d/1h7NnkPIihE_JuztP7uEcEK3T5JMcDHk4/view?usp=sharing), [Part 5](https://drive.google.com/file/d/1qxjFy2fPc72tkyJxupQ6EruvFR94txaf/view?usp=sharing), [Part 6](https://drive.google.com/file/d/1bzYpdEFhFlr1_uqMIwNKesJ7XAWRSB5O/view?usp=sharing)\n",
        "\n",
        "\n",
        "# Part 3: Generating and Testing a Predictive Model!\n",
        "\n",
        "Run the first code cell below to get everything ready. This sets up your cloud computer and installs the tools we need.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-06-16T14:44:50.874881Z",
          "start_time": "2019-06-16T14:44:38.616867Z"
        },
        "id": "CbVE99Ix34sv"
      },
      "source": [
        "# Be sure to run this critical first cell to import libraries and prepare our cloud computer!\n",
        "# Click the \"play\" button to the left or press Ctrl+Enter to execute.\n",
        "# If you haven't logged into Google, you'll be prompted.\n",
        "# Ignore any warning prompt if you see one and proceed.\n",
        "# This will then load the necessary libraries so we can analyze our data!\n",
        "\n",
        "# Install missing libraries\n",
        "\n",
        "%pip install mljar-scikit-plot xgboost imbalanced-learn -q\n",
        "\n",
        "# Essential imports\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as ply\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Scikit-learn and data preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn import metrics, svm\n",
        "\n",
        "# Metrics and plotting\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, precision_recall_curve,\n",
        "                             f1_score, auc, log_loss, recall_score, precision_score,\n",
        "                             average_precision_score, classification_report, accuracy_score,\n",
        "                             RocCurveDisplay, PrecisionRecallDisplay, confusion_matrix, ConfusionMatrixDisplay)\n",
        "\n",
        "import scikitplot as skplt\n",
        "from scikitplot.metrics import plot_roc_curve, plot_precision_recall_curve, plot_confusion_matrix\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Imbalanced-learn\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Google Colab-specific settings\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# Plotly settings\n",
        "import plotly.offline\n",
        "plotly.offline.init_notebook_mode(connected=True)\n",
        "\n",
        "# Display options for pandas DataFrame\n",
        "pd.options.display.max_columns = 50\n",
        "pd.options.display.max_rows = 30\n",
        "\n",
        "# Set seaborn default figure size\n",
        "sns.set(rc={'figure.figsize':(12, 6)})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "vhP7XthF34sx"
      },
      "source": [
        "\n",
        "# Data import\n",
        "\n",
        "As in Part 1 and Part 2, this notebook utilizes a dataset sourced from University of Virginia studies by Dr. Robert Schorling of several hundred rural African American patients. Additional information on this data set is available here:   \n",
        "> https://hbiostat.org/data/repo/diabetes.html   \n",
        "\n",
        "Using this data source, Dr. Robert Hoyt (https://data.world/rhoyt) assigned patients to a diabetes category if their hemoglobin A1c values were 6.5 or greater (https://data.world/informatics-edu/diabetes-prediction). The dataset  explored here is the modified version from Dr. Hoyt, almost ready to go for our explorations.\n",
        "\n",
        "Our next step: Let's retrieve the data to use in our Notebook!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmJEfaem34sx"
      },
      "source": [
        "# Run this cell to reference the website that is holding the diabetes data in a CSV (comma separated values) file!\n",
        "website = \"https://drive.google.com/uc?export=download&id=1PQM8eQnQpaJwe9mAVb_XBpZoWoA5nTlM\"\n",
        "\n",
        "# polyp example\n",
        "website_no = 'https://raw.githubusercontent.com/DrDavidL/dhds/main/colon_path_pred.csv'\n",
        "\n",
        "# The command below assigns the name dm_raw to the now read CSV file retrieved from the website!\n",
        "df_dm = pd.read_csv(website)\n",
        "\n",
        "# Let's view 10 rows of data and enable sorting for the columns. Click column headers to get a feel for the max/min for columns.\n",
        "# What's the maximum SBP? Lowest HDL? Note the Filter option at the top right. Click and filter to see how many patients are over 85.\n",
        "data_table.DataTable(df_dm, include_index=False, num_rows_per_page=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once we load the data, we’ll turn categories like \"male/female\" and \"diabetes/no diabetes\" into numbers (1 or 0). This is important because most machine learning models need numbers, not words.\n",
        "# Now, \"no diabetes\" will become \"0\" and \"diabetes\" will become \"1\" where they appear in the Diabetes column of our dataframe.\n",
        "\n",
        "# Replace categorical values in 'Diabetes' column with numerical values (0 and 1).\n",
        "df_dm['Diabetes'] = df_dm['Diabetes'].replace(['No diabetes', 'Diabetes'], [0, 1])\n",
        "\n",
        "# Replace categorical values in 'Gender' column with numerical values (1 for 'male', 0 for 'female').\n",
        "df_dm['Gender'] = df_dm['Gender'].replace(['male', 'female'], [1, 0])\n",
        "\n",
        "# Let's check that the categorical columns are now updated as integers with (1 or 0) for entries.\n",
        "print(f'Gender values:  \\n{df_dm[\"Gender\"].value_counts()} \\n')\n",
        "print(f'Diabetes values:  \\n{df_dm[\"Diabetes\"].value_counts()}')\n"
      ],
      "metadata": {
        "id": "U-F7Jshd5O6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH6MHebyMSEV"
      },
      "source": [
        "# Prior to running a model, let's view the correlations with presence of diabetes for each of the variables.\n",
        "\n",
        "# Calculate the correlation matrix for df_dm dataframe.\n",
        "corr_df = df_dm.corr()\n",
        "\n",
        "# Sort correlations with 'Diabetes' column in descending order and round to 3 decimal places.\n",
        "diabetes_corr = corr_df['Diabetes'].round(3).sort_values(ascending=False)\n",
        "\n",
        "# Print correlations with presence of diabetes for each variable.\n",
        "print(diabetes_corr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE97Ncelgj6c"
      },
      "source": [
        "Finding Relationships in the Data\n",
        "\n",
        "We’ll check which features (like glucose or cholesterol) are related to having diabetes.\n",
        "\n",
        "A high positive number means that as the feature increases, diabetes is more likely. A negative number means that as the feature increases, diabetes is less likely.\n",
        "\n",
        "For example:\n",
        "\n",
        "Glucose (0.689) has a strong positive relationship with diabetes.\n",
        "\n",
        "HDL cholesterol (-0.123) has a weak negative relationship with diabetes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another approach uses colors instead of numbers to pick out strong correlations.\n",
        "\n",
        "# Create a subplot with a specified size for the heatmap.\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# Define a colormap with diverging colors for the heatmap.\n",
        "cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "\n",
        "# Calculate the correlation matrix for df_dm dataframe.\n",
        "corr = df_dm.corr()\n",
        "\n",
        "# Create a mask to hide the upper triangle of the heatmap (repeated information).\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Plot the heatmap using seaborn's heatmap function.\n",
        "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,\n",
        "            mask=mask, cmap=cmap, vmax=.7, vmin=-.13, ax=ax)\n",
        "\n",
        "# Set plot parameters and labels.\n",
        "ax.set_title('Heatmap Showing Correlations between Variables')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ynWe2moo6WCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvyxVWAWWytz"
      },
      "source": [
        "**Using a Heatmap to See Relationships**\n",
        "\n",
        "A heatmap is a colorful chart that shows how different variables are related. It helps us quickly spot strong relationships.\n",
        "\n",
        "Look at the row labeled \"Diabetes\" in the heatmap. The darker blue areas mean strong positive relationships (like with glucose), and pink areas mean negative relationships (like with HDL)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Rw9TCoibim"
      },
      "source": [
        "# Getting Ready to Build a Model\n",
        "\n",
        "We want to teach a model to predict whether someone has diabetes based on their other health info.\n",
        "\n",
        "To do this:\n",
        "\n",
        "1. We split the data into two parts:\n",
        "\n",
        "  *   A `training set` (80%) to build the model\n",
        "\n",
        "  *   A `test set` (20%) to check how well it works\n",
        "\n",
        "2. We separate the data into inputs (like glucose, age, etc.) and outputs (whether or not the person has diabetes). We will use `trainData` and `testData` for the inputs respectively for the training and test data set. We'll then use `trainLabel` and `testLabel` are for the corresponding outputs (often called \"labels\"), i.e., whether or not a patient has diabetes.\n",
        "\n",
        "3. We scale the numbers so they’re all on a similar range. This helps the model treat all features fairly. Remember, our dataset reveals data about each patient. We will set the mean value at 0 and the standard deviation at 1. This normalization will help us compare the weight of the features inside our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign inputs and outputs\n",
        "# \"y\" is considered the output we'd like to predict. Here, it's whether or not the patient has Diabetes so we select that column from our dataset\n",
        "y = df_dm['Diabetes']\n",
        "\n",
        "# The inputs are \"X\" and are all the columns except for the 'Diabetes' column.\n",
        "X = df_dm.drop(columns=['Diabetes'])\n",
        "\n",
        "# Now we split our data into a \"training set\" where our model learns the relationship between the input variables and diabetes.\n",
        "# And, the other split is a \"testing set.\" This we hold apart from our model creation so it's pure for testing how good our model is!\n",
        "# There are many ways one can slip-up and, e.g., include the test data when using data statistics in the model creation. This is cheating!\n",
        "\n",
        "# Splitting the dataset into training and testing sets, with 80% for training and 20% for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,                       # Input features (all columns except 'Diabetes')\n",
        "    y,                       # Target output ('Diabetes' column)\n",
        "    random_state=42,         # Setting a random seed for reproducibility\n",
        "    shuffle=True,            # Shuffling the data before splitting\n",
        "    test_size=0.2,           # Percentage of data to allocate to the test set\n",
        "    stratify=df_dm['Diabetes']  # Preserving the proportion of diabetic and non-diabetic cases\n",
        ")\n",
        "# You can pick your favorite number for \"random_state\"! It is used for the consistency of the data split/model performance.\n",
        "# With the same random state value, the train/test datasets will look the same no matter how many times you run the code."
      ],
      "metadata": {
        "id": "fEKz2C_t4xB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's examine our training dataset! How many patients have DM? Is it a skewed, or imbalanced dataset?"
      ],
      "metadata": {
        "id": "vAIUqkdL6BWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the fractions of diabetic and non-diabetic patients in the training set\n",
        "print(f'Diabetes Fractions: \\n{y_train.value_counts(normalize=True).round(2)}\\n') # Provide proportion instead of actual counts\n",
        "\n",
        "# Plot a bar chart showing the counts of diabetic (1) and non-diabetic (0) patients in the training set\n",
        "y_train.value_counts().plot(kind='bar', title=\"Patients without (0) and with (1) Diabetes\") # Bar chart"
      ],
      "metadata": {
        "id": "2CJsKpt86Pwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making our first model!\n",
        "\n",
        "Only about 15% of patients in our training data have diabetes. That’s a big imbalance, which can make it harder for the model to learn. To fix this, we’ll use a method called SMOTE. It creates synthetic examples of patients with diabetes, so the data is more balanced.\n",
        "\n",
        "Next, we scale all the input numbers so they're on a similar range. For example, someone’s weight might be 200, while their waist/hip ratio might be 0.7. We want to make sure big numbers don’t unfairly influence the model just because of their size.\n",
        "\n",
        "Once that’s done, we’ll put everything into a pipeline—a series of steps that prepare the data and then train the model. The machine learning method we’ll use first is called logistic regression.\n",
        "\n",
        "We also have two options for training:\n",
        "\n",
        "  *   Use the entire training dataset at once\n",
        "  *   Or use a method called **stratified k-fold cross-validation**, which splits the training data into smaller pieces (called folds), trains the model on some folds, and tests it on others. This helps us get a more accurate idea of how well the model might perform on new data. We’ll use 5 folds for this.\n",
        "\n",
        "The next step will run this full process and show how our diabetes prediction model performs.\n",
        "\n"
      ],
      "metadata": {
        "id": "aPES8Mfd6dFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note the 3 ingredients in our pipeline for model creation. First, we address the imbalanced data by generating synthetic data using\n",
        "# SMOTE that retains characteristics of the diabetes patients already in the dataset. Then, we \"scale\" the values to lessen the impact of different value\n",
        "# ranges as mentioned above. Then, in the pipeline, we are going to use \"Logistic Regression\" to generate our first model!\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ['smote', SMOTE(random_state=11)],  # Step 1: Address imbalanced data using SMOTE\n",
        "    ['scaler', MinMaxScaler()],         # Step 2: Scale feature values using MinMaxScaler\n",
        "    ['classifier', LogisticRegression(random_state=11, max_iter=1000)]  # Step 3: Logistic Regression classifier\n",
        "])\n",
        "\n",
        "# Remember k-fold cross validation as mentioned above? This will slice our training data into 5 sections and pass each slice into through our pipeline.\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, # K value of your choice\n",
        "                                       shuffle=True, # Shuffle the data before splitting\n",
        "                                       random_state=11 # Random state of your choice\n",
        "                                   )\n",
        "\n",
        "# There are even more advanced techniques to \"tweak\" how our model works. Suffice it to say, we're going to try\n",
        "# a variety of these tweaks all at the same time, and then pick the best tweak possible!\n",
        "param_grid = {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}  # Hyperparameter grid for Logistic Regression\n",
        "grid_search = GridSearchCV(estimator=pipeline,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='roc_auc',  # Use ROC AUC for scoring\n",
        "                           cv=stratified_kfold,  # Use stratified k-fold cross-validation\n",
        "                           n_jobs=-1, refit=True)  # Use all CPU cores, refit with best parameters\n",
        "\n",
        "# Here we send our data into our pipeline! Find the best estimators.\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Lastly, let's name our best model setting. Get the best estimators and model.\n",
        "clf_lg = grid_search.best_estimator_\n",
        "\n",
        "# How did our model do? These steps gather all the generated predictions and probabilities.\n",
        "test_prob1 = clf_lg.predict_proba(X_test)[:, 1] # Make predictions (probability)\n",
        "train_prob1 = clf_lg.predict_proba(X_train)[:, 1]\n",
        "test_pred1 = clf_lg.predict(X_test) # Make predictions (class)\n",
        "train_pred1 = clf_lg.predict(X_train)\n",
        "\n",
        "# Here we calculate the training set accuracy of our best tweaked version.\n",
        "cv_score = grid_search.best_score_.round(3)\n",
        "\n",
        "# Here we calculate the test dataset performanc.\n",
        "test_score = grid_search.score(X_test, y_test).round(3)\n",
        "\n",
        "# Print out evaluation metrics\n",
        "print('Our Logistic Regression Model Metrics\\n')\n",
        "\n",
        "print('Accuracy (training) = {:.3f}'.format(cv_score))\n",
        "print('Accuracy (testing) = {:.3f}\\n'.format(test_score))\n",
        "\n",
        "# Generate ROC/AUC score, which is a more comprehensive evaluation criteria compared to accuracy\n",
        "print('AUC (training) = {:.3f}'.format(roc_auc_score(y_train, train_prob1)))\n",
        "print('AUC (testing) = {:.3f}\\n'.format(roc_auc_score(y_test, test_prob1)))\n",
        "\n",
        "# Generate F1 score, which is a another comprehensive evaluation criteria,\n",
        "# This score is made up by Precision(a score emphasize on false positive) and Recall(a score emphasize on false negative)\n",
        "print('F1 score (training) = {:.5f}'.format(f1_score(y_train, train_pred1)))\n",
        "print('F1 score (testing) = {:.5f}'.format(f1_score(y_test, test_pred1)))"
      ],
      "metadata": {
        "id": "hEGjXu2w9GQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy and F1 statistics\n",
        "\n",
        "When you read articles about machine learning models, you'll encounter these  terms:\n",
        "\n",
        "> Accuracy: The percent of correct predictions, overall, including positive and negative predictions. Higher values are better with the range being between 0 to 1.\n",
        "\n",
        "> AUC: AUC (Area Under Curve): Tells how well the model can separate diabetes from no-diabetes. A score near 1 is best.\n",
        "\n",
        "> F1 Score: Balances two things:\n",
        "  *   Precision: Of all the people the model said had diabetes, how many really did?\n",
        "  *   Recall: Of all the people who had diabetes, how many did the model catch?\n",
        "\n",
        "**Choosing the Best Threshold**\n",
        "\n",
        "These measures charaterize the model overall. When we deploy a model, say in an EHR to give a heads up that your patient may have diabetes, we can set a threshold for a specific risk level that will switch the predicted category from one to another.\n",
        "\n",
        "The model gives us a probability for each patient (like 52% chance of diabetes). We set a threshold (like 50%) to decide when to predict \"yes\" for diabetes. A higher threshold gives fewer false alarms (false positives), but may miss some real cases. A lower threshold catches more diabetes cases, but may also flag more people who don’t have it.\n",
        "\n",
        "Let's look at them and then we'll explain!\n"
      ],
      "metadata": {
        "id": "Qm1i9VmvDTZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This first line helps us see plots next to each other.\n",
        "fig, axs = plt.subplots(1,2)\n",
        "\n",
        "# Here we generate the ROC curve from the Training Dataset.\n",
        "RocCurveDisplay.from_estimator(clf_lg, X_train, y_train).plot(ax=axs[0])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Here we generate the ROC curve from the Testing Dataset.\n",
        "RocCurveDisplay.from_estimator(clf_lg, X_test, y_test).plot(ax=axs[1])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Set the title for the figure, displaying side-by-side ROC curves for training and testing datasets.\n",
        "fig.suptitle(\"\"\"Training Dataset ROC Curve                               \\\n",
        "            Testing Dataset ROC Curve\"\"\");\n"
      ],
      "metadata": {
        "id": "N9ycbhxzP4t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ROC Curves\n",
        "\n",
        "An ROC curve shows the trade-off between catching real diabetes cases (true positives) and avoiding false alarms (false positives).\n",
        "\n",
        "We want the curve to reach the top-left corner. That would mean the model is perfect!\n",
        "\n",
        "The AUC number tells us how close the curve gets to perfect. Our test AUC is about 0.86, which is pretty good.\n",
        "\n",
        "\n",
        "Next up: Precision-Recall curves:"
      ],
      "metadata": {
        "id": "N1hkkJJaZafF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This first line helps us see plots next to each other.\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "# Here we generate the Precision-Recall curve using the Training Dataset.\n",
        "PrecisionRecallDisplay.from_estimator(clf_lg, X_train, y_train).plot(ax=axs[0])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Here we generate the Precision-Recall curve using the Testing Dataset.\n",
        "PrecisionRecallDisplay.from_estimator(clf_lg, X_test, y_test).plot(ax=axs[1])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Set the title for the figure, displaying side-by-side Precision-Recall curves for training and testing datasets.\n",
        "fig.suptitle(\"\"\"    Training Precision-Recall Curve              \\\n",
        "            Testing Precision-Recall Curve\"\"\");\n"
      ],
      "metadata": {
        "id": "fOAxQ5bLtv8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision-Recall Curves\n",
        "\n",
        "This curve helps when we have imbalanced data (like in our case).\n",
        "\n",
        "It shows the trade-off between:\n",
        "  *   Precision: How many of the predicted diabetes cases were correct\n",
        "  *   Recall: How many actual diabetes cases the model found\n",
        "\n",
        "A perfect model would reach the top-right corner of this plot.\n",
        "\n"
      ],
      "metadata": {
        "id": "MPpzcGbdzVc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and functions\n",
        "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Generate predictions using the trained model on the test set\n",
        "predictions = clf_lg.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, predictions, labels=clf_lg.classes_)\n",
        "\n",
        "# Initialize ConfusionMatrixDisplay with computed confusion matrix and display labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_lg.classes_)\n",
        "\n",
        "# Plot the confusion matrix with a color map ('Purples')\n",
        "disp.plot(cmap='Purples')\n",
        "\n",
        "# Disable grid lines on the plot\n",
        "plt.grid(False)\n",
        "\n",
        "# Set the title for the plot\n",
        "plt.title(\"Confusion Matrix for Our Diabetes Prediction Model\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "acSQe7A6kOa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgjNuA2pLsxq"
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "This is a table that shows how many patients were correctly or incorrectly predicted:\n",
        "  *   Top-left: Correctly said \"no diabetes\"\n",
        "  *   Bottom-right: Correctly said \"yes, diabetes\"\n",
        "  *   Top-right: False alarms (predicted diabetes but they didn’t have it)\n",
        "  *   Bottom-left: Missed cases (they had diabetes but model said no)\n",
        "\n",
        "You want to see high numbers in the top-left and bottom-right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ_spOFKMr87"
      },
      "source": [
        "# Before you leave...\n",
        "\n",
        "1. Please complete the ***very brief*** statement of completion survey [here](https://forms.office.com/r/PhxaQ9q4Pm):   \n",
        "\n",
        "\n",
        "2. Check out the references for more information below!  \n",
        "\n",
        "3. Check out the **BONUS** machine learning models at the end, below references!\n",
        "\n",
        "Thank you!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "Fjwxku2M34s1"
      },
      "source": [
        "# References and more\n",
        "\n",
        "Perhaps you loved this so much, you want to make your own Colab notebooks! How would you do this???\n",
        "\n",
        "First, save a copy of this notebook so you can always refer back to copy the libraries and leverage the code used on future notebooks.\n",
        "\n",
        "Then, visit [here](https://colab.research.google.com/?utm_source=scs-index) for an overview and setup!\n",
        "\n",
        "Thank you!\n",
        "\n",
        "David Liebovitz, MD\n",
        "\n",
        "\n",
        "References:\n",
        "\n",
        "1. Bento C. Support Vector Machines explained with Python examples [Internet]. Medium. 2020 [cited 2021 Nov 11]. Available from: https://towardsdatascience.com/support-vector-machines-explained-with-python-examples-cb65e8172c85\n",
        "\n",
        "\n",
        "2. Brownlee J. How to Use ROC Curves and Precision-Recall Curves for Classification in Python [Internet]. Machine Learning Mastery. 2018 [cited 2021 Nov 7]. Available from: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
        "\n",
        "> - This is a great resource for explaining ROC curves and coding for them. (Other pages on the site are fantastic, too.)\n",
        "\n",
        "\n",
        "3. Dhandhania K. End-to-End Data Science Example: Predicting Diabetes with Logistic Regression [Internet]. Medium. 2018 [cited 2021 Nov 7]. Available from: https://towardsdatascience.com/end-to-end-data-science-example-predicting-diabetes-with-logistic-regression-db9bc88b4d16\n",
        "\n",
        "> - I came across this website as I was well on my way. There are many similarities to the approach followed above that is applied to a different data set. I applied the normalization, heatmap, and correlations methods discussed here.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3nzbs8X8DK8"
      },
      "source": [
        "# APPENDIX  \n",
        "\n",
        "Here are examples applying other machine learning algorithms to our data set to generate predictive models:\n",
        "\n",
        "> - Support Vector Machine  \n",
        "> - XGBoost\n",
        "> - Random Forest\n",
        "> - Gaussian Naive Bayes\n",
        "\n",
        "The model's accuracy doesn't change too much, although, we didn't have that large a data set and some approaches work optimally with larger or more complex data. Sometimes, as here, logistic regression appears fine!\n",
        "\n",
        "It's also possible to combine models and \"vote.\" So, e.g., 2/3 models are necessary to make the call. This is an example of an ensemble method. Three \"heads\" sometimes better than one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCM0nIoj7-Wc"
      },
      "source": [
        "An SVM (support vector machine) example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX29GwvM1l0Z"
      },
      "source": [
        "# Define a pipeline for SVM model including SMOTE for data balancing, MinMaxScaler for feature scaling, and SVM classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ['smote', SMOTE(random_state=11)],  # Step 1: Address imbalanced data using SMOTE\n",
        "    ['scaler', MinMaxScaler()],         # Step 2: Scale feature values using MinMaxScaler\n",
        "    ['classifier', svm.SVC(random_state=11, max_iter=1000)]  # Step 3: SVM classifier\n",
        "])\n",
        "\n",
        "# Define Stratified K-Fold cross-validation for robust evaluation\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
        "\n",
        "# Define parameter grid for SVM hyperparameter tuning\n",
        "param_grid = {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Setup GridSearchCV to find best SVM model based on ROC AUC scoring\n",
        "grid_search = GridSearchCV(estimator=pipeline,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='roc_auc',\n",
        "                           cv=stratified_kfold,\n",
        "                           n_jobs=-1\n",
        "                           # If n_jobs = -1, it uses all available cores on your machine for parallel execution.\n",
        "                           # If n_jobs = 1, it runs the grid search using a single core (no parallelism).\n",
        "                           # If n_jobs > 1, it specifies the exact number of cores to use for parallel execution.\n",
        "                           )\n",
        "\n",
        "# Fit GridSearchCV on training data to find the best model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best cross-validation score from GridSearchCV\n",
        "cv_score = grid_search.best_score_.round(3)\n",
        "\n",
        "# Evaluate best model on test data\n",
        "test_score = grid_search.score(X_test, y_test).round(3)\n",
        "\n",
        "# Get best estimator (model) from GridSearchCV\n",
        "clf_svm = grid_search.best_estimator_\n",
        "\n",
        "# Print SVM model metrics\n",
        "print(f'SVM Metrics: \\nTraining ROC AUC: {cv_score}\\nTesting ROC AUC: {test_score}\\n')\n",
        "\n",
        "# Generate predictions on test set using the best SVM model\n",
        "predictions = clf_svm.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix for test predictions\n",
        "cm = confusion_matrix(y_test, predictions, labels=clf_svm.classes_) # clf_svm.classes_ will get the prediction classes\n",
        "\n",
        "# Initialize ConfusionMatrixDisplay with computed confusion matrix and display labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_svm.classes_)\n",
        "\n",
        "# Create a figure with two subplots for ROC curve and confusion matrix side-by-side\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "# Generate and plot the ROC curve for the best SVM model on the Testing Dataset\n",
        "RocCurveDisplay.from_estimator(clf_svm, X_test, y_test).plot(ax=axs[0])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Set the title for the figure, displaying SVM Testing ROC Curve and SVM Confusion Matrix side by side.\n",
        "fig.suptitle(\"\"\"    SVM Testing ROC Curve              \\\n",
        "            SVM Confusion Matrix\"\"\")\n",
        "\n",
        "# Disable grid lines on the confusion matrix plot.\n",
        "plt.grid(False)\n",
        "\n",
        "# Plot the confusion matrix with a color map ('Purples')\n",
        "disp.plot(cmap='Purples', ax=axs[1])\n",
        "\n",
        "# Display the figure containing both plots.\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of Support Vector Machines (SVM):**\n",
        "1. Effective in High-Dimensional Spaces: SVMs perform well in high-dimensional spaces, making them suitable for complex problems where the number of features is large.\n",
        "\n",
        "2. Versatile Kernel Options: SVMs can use different kernel functions to handle non-linear decision boundaries, including linear, polynomial, radial basis function (RBF), and sigmoid kernels.\n",
        "\n",
        "3. Effective in Non-Linear Classifications: With appropriate kernels, SVMs can model complex decision boundaries that other algorithms may struggle with.\n",
        "\n",
        "4. Robust Against Overfitting: SVMs have regularization parameters that help prevent overfitting, even in high-dimensional spaces with small sample sizes.\n",
        "\n",
        "**Limitations of Support Vector Machines (SVM):**\n",
        "1. Computational Intensity: Training an SVM can be time-consuming, especially on large datasets. The complexity of SVMs also increases with the size of the dataset.\n",
        "\n",
        "2. Difficulty in Choosing Kernels: Selecting the right kernel function and tuning its parameters can be challenging and requires domain knowledge and experimentation.\n",
        "\n",
        "3. Limited Scalability: SVMs may not perform well with datasets that have millions of examples or more, as the training time increases significantly."
      ],
      "metadata": {
        "id": "A6M4i9RcQpHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An XGBoost example"
      ],
      "metadata": {
        "id": "wMJ59hohuD3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pipeline for XGBoost model including SMOTE for data balancing, MinMaxScaler for feature scaling, and XGBoost classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ['smote', SMOTE(random_state=11)],  # Step 1: Address imbalanced data using SMOTE with a fixed random state for reproducibility\n",
        "    ['scaler', MinMaxScaler()],         # Step 2: Scale feature values using MinMaxScaler to ensure all features are on the same scale\n",
        "    ['classifier', XGBClassifier(random_state=11, max_iter=1000)]  # Step 3: XGBoost classifier with a fixed random state and maximum iterations set to 1000\n",
        "])\n",
        "\n",
        "# Define Stratified K-Fold cross-validation for robust evaluation\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
        "\n",
        "# Define parameter grid for XGBoost hyperparameter tuning\n",
        "param_grid = {'classifier__learning_rate': [0.001, 0.01, 0.1, 1],  # Example parameter grid for learning rate\n",
        "              'classifier__max_depth': [3, 5, 7]}  # Example parameter grid for max depth\n",
        "\n",
        "# Setup GridSearchCV to find the best XGBoost model based on ROC AUC scoring\n",
        "grid_search = GridSearchCV(estimator=pipeline,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='roc_auc',\n",
        "                           cv=stratified_kfold,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on training data to find the best model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best cross-validation score from GridSearchCV\n",
        "cv_score = grid_search.best_score_.round(3)\n",
        "\n",
        "# Evaluate best model on test data\n",
        "test_score = grid_search.score(X_test, y_test).round(3)\n",
        "\n",
        "# Get best estimator (model) from GridSearchCV\n",
        "clf_xgb = grid_search.best_estimator_\n",
        "\n",
        "# Print XGBoost model metrics\n",
        "print(f'XGB Metrics: \\nTraining ROC AUC: {cv_score}\\nTesting ROC AUC: {test_score}\\n')\n",
        "\n",
        "# Generate predictions on test set using the best XGBoost model\n",
        "predictions = clf_xgb.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix for test predictions\n",
        "cm = confusion_matrix(y_test, predictions, labels=clf_xgb.classes_)\n",
        "\n",
        "# Initialize ConfusionMatrixDisplay with computed confusion matrix and display labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_xgb.classes_)\n",
        "\n",
        "# Create a figure with two subplots for ROC curve and confusion matrix side-by-side\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "# Generate and plot the ROC curve for the best XGBoost model on the Testing Dataset\n",
        "RocCurveDisplay.from_estimator(clf_xgb, X_test, y_test).plot(ax=axs[0])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Set the title for the figure, displaying XGB Testing ROC Curve and XGB Confusion Matrix side by side.\n",
        "fig.suptitle(\"\"\"XGB Testing ROC Curve          \\\n",
        "            XGB Confusion Matrix\"\"\")\n",
        "\n",
        "# Disable grid lines on the confusion matrix plot.\n",
        "plt.grid(False)\n",
        "\n",
        "# Plot the confusion matrix with a color map ('Purples')\n",
        "disp.plot(cmap='Purples', ax=axs[1])\n",
        "\n",
        "# Display the figure containing both plots.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aPFRuFHAuF8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of XGBoost:**\n",
        "\n",
        "1. High Performance: XGBoost is known for its high computational efficiency and speed due to its optimized algorithms and parallelization.\n",
        "\n",
        "2. Handles Missing Data: It has built-in capabilities to handle missing data, which reduces the need for data preprocessing.\n",
        "\n",
        "3. Regularization: XGBoost includes regularization techniques such as L1 and L2 regularization to prevent overfitting.\n",
        "\n",
        "4. Flexibility: Supports various objective functions and evaluation metrics, making it adaptable to different types of problems.\n",
        "\n",
        "**Limitations of XGBoost:**\n",
        "\n",
        "1. Complexity: The hyperparameter tuning process can be complex and time-consuming due to the large number of parameters.\n",
        "\n",
        "2. Sensitive to Noisy Data: It can overfit noisy datasets if not properly tuned or regularized.\n",
        "\n",
        "3. Black Box Nature: Similar to other ensemble methods, XGBoost is less interpretable compared to simpler models like linear regression or decision trees."
      ],
      "metadata": {
        "id": "u3nc6pvcQRxX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTUOIKhn76Cc"
      },
      "source": [
        "A Random Forest example:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Random Forest Classifier with specified parameters\n",
        "rfc1 = RandomForestClassifier(\n",
        "    n_estimators=20,   # Number of trees in the forest (default is 100). More trees generally improve performance but increase computation time.\n",
        "    max_depth=4,       # Maximum depth of each tree in the forest (default is None, which expands nodes until all leaves are pure or until all leaves contain less than min_samples_split samples).\n",
        "    max_features=14,   # Maximum number of features to consider when splitting a node. Typically, the square root of the total number of features is a good starting point (default is 'auto', which uses all features).\n",
        "    bootstrap=True,    # Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree (default is True).\n",
        "    random_state=18\n",
        ")\n",
        "# You can also use GridSearch method to find the best parameters!\n",
        "\n",
        "# Train the Random Forest model on the training data\n",
        "rfc1.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test and training data\n",
        "pred = rfc1.predict(X_test)\n",
        "pred_t = rfc1.predict(X_train)\n",
        "\n",
        "# Print accuracy scores for training and testing\n",
        "print(\"Training Accuracy for Random Forest: \", accuracy_score(y_train, pred_t))\n",
        "print(\"Testing Accuracy for Random Forest: \", accuracy_score(y_test, pred))\n",
        "\n",
        "# Create a figure with two subplots for ROC curve and confusion matrix side-by-side\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "# Generate and plot the ROC curve for the Random Forest model on the Testing Dataset\n",
        "RocCurveDisplay.from_predictions(y_test, pred).plot(ax=axs[0])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Compute confusion matrix for test predictions\n",
        "cm = confusion_matrix(y_test, pred, labels=rfc1.classes_)\n",
        "\n",
        "# Initialize ConfusionMatrixDisplay with computed confusion matrix and display labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rfc1.classes_)\n",
        "\n",
        "# Plot the confusion matrix with a color map ('Purples')\n",
        "disp.plot(cmap='Purples', ax=axs[1])\n",
        "\n",
        "# Disable grid lines on the confusion matrix plot.\n",
        "plt.grid(False)\n",
        "\n",
        "# Display the figure containing both plots.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DRkFvO9K2EG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Advantages:**\n",
        "\n",
        "1. High Accuracy:\n",
        "Random Forest generally produces highly accurate predictions by aggregating the results from multiple decision trees. It reduces overfitting by averaging or voting, which improves generalization.\n",
        "\n",
        "\n",
        "2. Robust to Overfitting:\n",
        "Due to its ensemble nature and the randomness introduced during tree construction, Random Forest is less prone to overfitting compared to individual decision trees.\n",
        "\n",
        "3. Handles Missing Values and Outliers:\n",
        "Random Forest has mechanisms to handle missing data and maintain accuracy even when a large proportion of data is missing.\n",
        "\n",
        "**Limitations:**\n",
        "1. Model Interpretability:\n",
        "While Random Forest provides feature importance, it is more challenging to interpret compared to a single decision tree. Understanding individual predictions can be complex.\n",
        "2. Computational Complexity:\n",
        "Training a large number of decision trees can be computationally expensive and time-consuming, especially if the number of trees and depth of each tree are large.\n",
        "3. Not Suitable for Very Sparse Data:\n",
        "It may not perform well on very sparse datasets where the number of features is much larger than the number of samples."
      ],
      "metadata": {
        "id": "Qw23VMdBPQKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "QkRJ5aBG7n7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pipeline for Gaussian Naive Bayes model including SMOTE for data balancing, MinMaxScaler for feature scaling, and Gaussian Naive Bayes classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ['smote', SMOTE(random_state=11)],      # Step 1: Address imbalanced data using SMOTE with a fixed random state for reproducibility\n",
        "    ['scaler', MinMaxScaler()],             # Step 2: Scale feature values using MinMaxScaler to ensure all features are on the same scale\n",
        "    ['classifier', GaussianNB()]            # Step 3: Gaussian Naive Bayes classifier\n",
        "])\n",
        "\n",
        "# Define Stratified K-Fold cross-validation for robust evaluation\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
        "\n",
        "# Define parameter grid for Gaussian Naive Bayes (var_smoothing is a parameter that helps with numerical stability by adding a small value to variances)\n",
        "param_grid = {\n",
        "    'classifier__var_smoothing': np.logspace(0, -9, num=30)  # Vary var_smoothing parameter across a range of values\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV to find the best Gaussian Naive Bayes model based on ROC AUC scoring\n",
        "grid_search = GridSearchCV(estimator=pipeline,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='roc_auc',\n",
        "                           cv=stratified_kfold,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on training data to find the best model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best cross-validation score from GridSearchCV\n",
        "cv_score = grid_search.best_score_.round(3)\n",
        "\n",
        "# Evaluate best model on test data\n",
        "test_score = grid_search.score(X_test, y_test).round(3)\n",
        "\n",
        "# Get best estimator (model) from GridSearchCV\n",
        "clf_gnb = grid_search.best_estimator_\n",
        "\n",
        "# Print Gaussian Naive Bayes model metrics\n",
        "print(f'Training Accuracy Gaussian Naive Bayes: {cv_score}\\nTesting Accuracy Gaussian Naive Bayes: {test_score}\\n')\n",
        "\n",
        "# Generate predictions on test set using the best Gaussian Naive Bayes model\n",
        "predictions = clf_gnb.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix for test predictions\n",
        "cm = confusion_matrix(y_test, predictions, labels=clf_gnb.classes_)\n",
        "\n",
        "# Create a figure with two subplots for ROC curve and confusion matrix side-by-side\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "# Generate and plot the ROC curve for the best Gaussian Naive Bayes model on the Testing Dataset\n",
        "RocCurveDisplay.from_estimator(clf_gnb, X_test, y_test).plot(ax=axs[0])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Set the title for the figure, displaying GNB Testing ROC Curve and GNB Confusion Matrix side by side.\n",
        "fig.suptitle(\"\"\"GNB Testing ROC Curve          \\\n",
        "            GNB Confusion Matrix\"\"\")\n",
        "\n",
        "# Initialize ConfusionMatrixDisplay with computed confusion matrix and display labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_gnb.classes_)\n",
        "\n",
        "# Disable grid lines on the confusion matrix plot.\n",
        "plt.grid(False)\n",
        "\n",
        "# Plot the confusion matrix with a color map ('Purples')\n",
        "disp.plot(cmap='Purples', ax=axs[1])\n",
        "\n",
        "# Display the figure containing both plots.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZbsznmsX7nOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another Gaussian Naive Bayes\n",
        "\n",
        "Simple deployment - no grid search, SMOTE or cross validation."
      ],
      "metadata": {
        "id": "4bDoVruU_vgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Instantiate Gaussian Naive Bayes classifier\n",
        "classifier = GaussianNB()\n",
        "\n",
        "# Train the Gaussian Naive Bayes classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test and training data\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred_t = classifier.predict(X_train)\n",
        "\n",
        "# Calculate confusion matrix for test predictions\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate accuracy scores for training and testing\n",
        "ac = accuracy_score(y_test, y_pred)\n",
        "act = accuracy_score(y_train, y_pred_t)\n",
        "\n",
        "# Print accuracy scores for training and testing\n",
        "print(\"Naive Bayes Training Accuracy: \" + str(act))\n",
        "print(\"Naive Bayes Testing Accuracy: \" + str(ac))\n",
        "\n",
        "# Create a figure with two subplots for ROC curve and confusion matrix side-by-side\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "# Generate and plot the ROC curve for the Gaussian Naive Bayes model on the Testing Dataset\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred).plot(ax=axs[0])\n",
        "\n",
        "# Close the plot to avoid displaying unwanted duplicate plots.\n",
        "plt.close()\n",
        "\n",
        "# Initialize ConfusionMatrixDisplay with computed confusion matrix and display labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classifier.classes_)\n",
        "\n",
        "# Plot the confusion matrix with a color map ('Purples')\n",
        "disp.plot(cmap='Purples', ax=axs[1])\n",
        "\n",
        "# Disable grid lines on the confusion matrix plot.\n",
        "plt.grid(False)\n",
        "\n",
        "# Display the figure containing both plots.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3TRvJqKm71w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian NB**\n",
        "\n",
        "***Advantages:***\n",
        "\n",
        "Efficiency: Gaussian NB is computationally efficient and can handle large datasets with high-dimensional feature spaces.\n",
        "\n",
        "Simple and Fast: It's straightforward to implement and works well with small amounts of training data.\n",
        "\n",
        "\n",
        "***Limitations:***\n",
        "\n",
        "\n",
        "Independence Assumption: If features are strongly correlated, the model's performance can be affected negatively.\n",
        "\n",
        "Gaussian Assumption: If the feature distributions are not Gaussian, Gaussian NB might not model the data well."
      ],
      "metadata": {
        "id": "xzIHBD9cORQo"
      }
    }
  ]
}